數學背景A數學背景A
A.1

複雜度分析與 O( )符號

資訊科學家們經常會面臨這項工作：對演算法進行比較，以瞭解演算法能執行多快，需要多少
記憶體。這類工作有兩種解決方法。第一種方法是效能測試 
(benchmarking)——在電腦上執行演算
法，並測量以秒計的執行速度，及以 
byte計的消耗記憶體。最終來說，效能測試是真正事關重要
的東西，但可能會因過於特定而無法令人滿意：它測量的是，以特定程式語言編寫的一段特定程
式，在特定的編譯器和特定的輸入資料下，在一台特定的電腦上執行的效能。根據效能測試提供的
單一結果，要預測該演算法在其他編譯器、電腦或者資料集上的效能，有可能還是很困難。第二種
方法則仰賴數學的演算法分析，而無關特定的實作和輸入，如下討論。 


A.1.1漸近分析
我們透過下面的例子——對一個數列進行求和的一段程式——來考慮演算法分析。


分析的第一步是對輸入進行簡化萃取，以找到能夠反映輸入大小的某個或者某些參數。在這個例子
中，輸入可用序列的長度來描述，記作 
n。第二步是要對演算法實作進行簡化萃取，以找到某種能
夠反映出演算法執行時間，但不限定在特定編譯器或電腦的度量。對於 
SUMMATION程式，這個度
量可以就是所執行的程式碼行數，或者也可以更複雜，如測量演算法所執行的加法、賦值、陣列取
用及分支等執行次數。兩種方式都能給出以輸入大小為函數的一個演算法執行步驟總數的表示法。
我們把這種表示法記為 
T(n)。如果我們計數程式碼的行數，則在這個例子中會得到 
T(n)=2n+2。

如果所有的程式都像 
SUMMATION這麼簡單，那麼演算法分析就是一個輕而易舉的領域了。但
是有兩個問題使其更加複雜。首先，很少能找到一個類似 
n這樣的參數，能夠完全描述演算法所執
行的步驟數。反之，我們通常頂多只能計算出最差情況 
Tworst(n)或者平均情況 
Tavg(n)。計算平均情況
是指，分析者必須假定出輸入的某種分佈。 



.App-2..App-2.
人工智慧 
–現代方法 
3/E

第二個問題在於，演算法有抗拒精確分析的傾向。在這種情況下，我們只好退而訴諸近似法。
我們稱演算法 
SUMMATION是 
O(n)，指的是除了幾個 
n值很小的可能例外，此度量最多為 
n乘以
一個常數。更正式地說，

對於所有的 
n > n0，如果存在某個 
k使得 
T(n).kf(n)，則 
T(n)是 
O(f(n))。 


O()符號為我們提供了所謂的漸近分析(asytomptoic analysis)。我們可以毫無疑問地說，在 
n趨近於
無窮大時，O(n)演算法要比 
O(n2)演算法好。單一的效能測試數據是無法證實如此聲稱。 


O()符號簡化萃取了常數因數，這使得它比 
T()符號更易於使用，但也較不精確。例如，長期來
看 
O(n2)演算法恆比 
O(n)演算法差，但如果這兩種演算法為 
T(n2+1)和 
T(100n+1000)，則當 
n<110時， 
O(n2)演算法其實比較好。

儘管有這個缺點，在演算法分析中，漸近分析是最廣為使用的工具。就是因為演算法同時簡化
萃取了精確的操作次數(藉由忽略常數因數 
k)，及輸入的精確內容(藉由只考慮輸入大小 
n)，使得分
析在數學上可行。符號 
O()是分析的精確度與簡易性間的一種很好的折衷。 


A.1.2 NP及本質上難題
演算法分析和 
O()符號使得我們能夠討論一個特定演算法的效率。然而，它並沒有告訴我們，
對於眼前的問題是否可能有更好的演算法。複雜度分析(complexity analysis)的領域所分析的是問題，
而不是演算法。第一個明顯的區分是在兩種問題間：一種問題可以在多項式時間內解決，而另一種
問題無論使用什麼演算法也不能在多項式時間內解決。多項式問題——也就是那些對於某個 
k而能
夠在 
O(n k)時間內解決的問題——這類別的問題被稱為 
P。有時候這些問題也被稱為「容易」(easy)
問題，因為這個類別包含了比如需 
O(log n)或 
O(n)的執行時間就可解決的問題。不過它也包含了所
需時間為 
O(n1000)的問題，因此我們不能過於字面地理解「容易」一詞。

另一個重要的問題類別是 
NP，即不確定多項式問題 
(nondeterministic polynomial problem)所形成
的類別。如果存在某個演算法，能夠猜測出一個問題的解，並在多項式時間內驗證這個猜測是否正
確，則這個問題屬於 
NP。想法是這樣：如果你有任意多的處理器，以致於能夠同時試驗所有的猜測，
或者你幸運到能夠總是在第一次就猜對，那麼 
NP問題就變成了 
P問題。資訊科學中一個懸而未決
的最大問題就是，在沒有無限多的處理器或不是全知猜測時， 
NP類別是否等同於 
P類別。絕大部分
電腦科學家都確信 
P≠NP；確信 
NP問題是本質上難題，且沒有多項式時間演算法能解它。不過這點
從未得到證明。

對於 
P是否等於 
NP有興趣的人，有注意到 
NP中一個稱為 
NP-complete問題的子類別。此處所
用的「complete」一詞是「最極端」的意思，因此它所指的是 
NP類別中最難的問題。已經證明出，
要嘛所有的 
NP-complete問題都是 
P問題，要嘛一個也不是。這使得此類別在理論上很有趣，但這
類別在實務中也很令人感興趣，因為很多重要的問題都已知為 
NP-complete。一個例子是可滿足性問
題(satisfiability problem)：給定一條命題邏輯語句，是否有一個對語句中命題符號的真假值的賦值方
式，可使該語句為真？除非奇蹟出現且 
P = NP，否則不可能有任何演算法能在多項式時間內解決所


附錄 


.App-3. 
有的可滿足性問題。不過，人工智慧更感興趣的是，是否存在一個演算法，能夠有效解決從預先確
定的分佈中得出的典型問題；就如我們在第 
7章看到的，有像 
WALKSAT這樣的演算法，在很多問
題上都表現得相當不錯。

在以下意義，co-NP類別與 
NP是互補的：在 
NP中的每個決策問題(decision problem)，都在 
co-NP
中有一個對應的問題，且「是」與「否」的回答相反。我們知道， 
P問題同時是 
NP及 
co-NP兩者的
子集，而人們也相信有屬於 
co-NP但不屬於 
P的問題。co-NP-complete問題是 
co-NP問題中最難的
問題。 


#P問題類別(讀作「sharp P」)是與 
NP中的決策問題相對應的計數問題集合。決策問題的答案
為「是」或「否」：這個 
3-SAT公式是否有解？而計數問題的答案是一個整數：滿足這個 
3-SAT公
式的解有多少個？在某些情況下，計數問題要比決策問題困難得多。例如，可以在時間 
O(V E)內確
定出，一個二部圖 
(bipartite graph)是否存在完美配對(這個二部圖具有 
V個頂點和 
E條邊)，但「這個
二部圖有多少完美配對」的計數問題則是 
#P-complete問題，也就是說它和任何 
#P中的問題一樣難，
因此至少也和任何 
NP問題一樣難。

另一類是 
PSPACE問題——即那些即使在一台不確定(nondeterministic)的機器上，也需要多項式
容量空間的問題。人們相信 
PSPACE難題比 
NP-complete問題更糟糕，雖然結果可能是 
NP 
= PSPACE，就如結果可能是 
P = NP一樣。 


向量、矩陣和線性代數

數學家將向量定義為向量空間的成員，不過我們將使用一個更具體的定義：一個向量是值的有
序序列。例如，在二維空間中，我們有像 
x=.3,4.和 
y=.0,2.這樣的向量。遵循慣例用法，我們用粗體
字母代表向量，雖然有些作者是在向量上加一個箭頭或橫槓： 
x ..或 
y。我們用下標來註明使用向量
的元素：z=.z1,z2,…,zn..有一點會令人困惑：本書是由很多子領域所構成的綜合性內容，各子領域會
個別將其序列稱為向量(vectors)、數列(lists)或數值組(tuples)，且個別使用符號.1,2.、[1, 2]或(1, 2)。

向量的兩種基本運算是向量加法和純量乘法(scalar multiplication)。向量加法 
x+y對逐個元素求
和：x+y=.3+0,4+2.=.3,6.。純量乘法則將向量的每一個元素乘上一個常數：5x=.5×3,5×4.=.15,20.。

向量的長度寫作|x|，為對其所有元素的平方和取平方根：|x|= 32 + 
42 = 5。兩個向量的點積 
x.y 
(dot product，也稱為純量積)是兩個向量對應元素乘積的和，也就是，x.y=Σi xi yi，或者在我們這個
特定的例子中是 
x.y=3×0+4×2=8。

向量經常被詮釋為 
n維歐幾里德空間中的一條有向線段(箭頭)。向量加法遂相當於將一個向量的
末端放到另一個向量的首端，而點積 
x.y則等於|x| |y|cos θ，其中 
θ是 
x和 
y之間的夾角。

矩陣是排列成行和列的值所形成的矩形陣列。這裡是一個 
3×4的矩陣 
A： 


. 
AA AA .

1,1 1,2 1,3 1,4 

..

AAAA

. 
2,1 2,2 2,3 2,4 . 


..

AA AA

. 
3,1 3,2 3,3 3,4 . 


Aij,的第一個下標指列，第二個指行。在程式語言中，常把 
A,寫作 
A[i,j]或者 
A[i][j]。

ij 


.App-4..App-4.
人工智慧 
–現代方法 
3/E

+ 
A +

兩矩陣之和的定義是利用到將兩者的對應元素作相加；例如 
(AB)ij, = 
ij , Bij。(若 
A及 
B

, 

ij 。矩陣乘法 
(兩個矩陣

的大小不同，則無法定義和 
)。我們也可以定義矩陣的純量乘法： 
()cA ij, =cA, 
的乘積)比較複雜。乘積 
AB只有當 
A的大小為 
a×b，而 
B的大小為 
b×c時才有定義 
(也就是說，第
二個矩陣的列數等於第一個矩陣的行數)；乘積的結果是一個 
a×c矩陣。如果兩個矩陣有適當對應的
大小，則結果為 


(AB)i,k =ΣAi,jBj,k 
j 


矩陣乘法不是可交換的，即使是方陣： 
AB ≠BA，這是一般而言的結果。然而，是滿足分配的： 
AB C =( xy。

() A BC) 。注意到，點積能以轉置及矩陣乘法來表示： 
xy.=T 
單位矩陣 
I是當 
i= j時元素 
Ii, j等於 
1，否則等於 
0。其具有一性質為，對於所有 
A， 
AI =A。 
.1A.1T, 。方陣 
A的

A的轉置，記作 
AT，是將 
A的列變行而得，反之亦可得；或者更正式地說， 
Aij =Aij , 
逆矩陣是滿足 
AA =I的另一個方陣 
。對於一個奇異矩陣(singular matrix)，不存在逆矩陣。而對
於非奇異矩陣，可在 
O(n3)時間內算得逆矩陣。

矩陣是用以在 
O(n3)時間內求解線性方程式系統；求解時間由係數矩陣的求逆所控制。考慮以下
方程組，我們希望求一組解 
x, y和 
z： 


+2x +yz 8
.= 
.3x .y +2z=.11 
.2x +y +2z=.3 


我們可將此系統表為矩陣方程式 
Ax = b，其中 


21 .1 x .8

. 
... 
. 
. 
.....


A 3 12, x y, b=.11 

=.. 
= 


. 
... 
..

. 
.....

.212 z .3

. 
..... 


A.1.1.1 
.1

欲解 
Ax = b，兩邊同乘 
，而得 
AAx =Ab，化簡得 
xAb。對 
A求逆後再乘 
b，得到答案

=

為： 


x 2

... 
. 
... 
. 


x =y = 
3

... 
.

... 
.

z .1

... 
. 



附錄 


.App-5. 
機率分布 

機率是在一組滿足以下 
3條公理的事件上的量度： 


1. 
每件事件的量度都介於 
0和 
1之間。我們記作 
0.P(X=xi).1，其中 
X是一個表示事件的隨機變數， 
xi是 
X的一個可能值。一般而言，隨機變數用大寫字母表示，其值用小寫字母表示。 
2.整個集合的量度等於 
1；也就是說， 
. 
1(niiPXx==) = 
1 
3. 
互斥事件的聯集其機率等於個別事件的機率和，也就是說， 
P(X=x1 . 
X=x2)=P(X=x1)+P(X=x2)，其中 
x1和 
x2是互斥的。
機率模型的組成為，一個兩兩互斥的可能結果所成的樣本空間，配上一個對每個結果的機率量
度。例如，在關於明天天氣的模型裡，可能結果有 
sunny(晴天)、cloudy(陰天)、rainy(雨天)、snowy(雪
天)。這些可能結果的子集合構成事件。例如，降水事件就是子集合{rainy, snowy}。

我們用 
P(X)表示由值 
.P(X=x1),…,P(X=xn).組成的向量。我們也將 
P(Xi ) 簡寫為 
()，將

= 
xPxi 
Σ1(niiPXx==) 簡寫為 
ΣxP x

() 。

條件機率 
P(B|A)定義為 
P(B∩A)/P(A)。如果 
P(B|A)=P(B)(或者等價地， 
P(A|B)=P(A))，則 
A和 
B
是條件獨立的。連續隨機變數的值有無限個，而除非存在突尖點 
(point spikes)，否則任何值的機率都
是 
0。因此，我們定義機率密度函數——也記作 
P()，不過它的含義和離散機率函數稍有不同。一個
隨機變數 
X的密度函數 
P(x)[可看作 
P(X=x)]是直觀地定義為，X落入 
x附近區間的機率除以此區間
的寬度後，所得比值在區間寬度趨近於 
0時的極限值： 


() = 
lim Px . 
X . 
x +dx )/ dx 

Px (

dx→0 

對於所有 
x，這個密度函數都一定為非負，並且必滿足 


() = 
1

PX dx 

∫∞
.∞

我們也可以定義累積機率密度函數 
X ()

Fx，即隨機變數小於 
x的機率： 


()()xXPXx=.=∫Pu du 

Fx 
()

.∞ 


注意到，機率密度函數是有單位的，而離散機率函數沒有單位。例如，如果 
X是以秒計量的，那麼
機率密度以 
Hz(即 
1/s)計量。如果 
X之值是以公尺為單位的三維空間中的一個點，那麼密度的單位
是 
1/m3。

一種非常重要的機率分佈是高斯分佈，也稱為常態分佈。一個具有平均值 
μ及標準差 
σ(因此變
異數為 
σ2)的高斯分佈定義為： 


1( x μ 
) /(2 σ 
)

() = 
e.. 
22

Px 

σ 
2π 



.App-6..App-6.
人工智慧 
–現代方法 
3/E

其中 
x是一個從–∞到+∞的連續隨機變數。若 
μ 
= 0且 
σ2 = 1，我們便得到稱為標準常態分佈的特例。
對於一個 
d維向量 
x上的分佈，存在多變量高斯分佈(multivariate Gaussian distribution)： 


1T .1

1 .((x. 
μ) Σ 
(x. 
μ))
P()x = 
e2 


(2) | π 
n Σ| 
其中 
μ是平均值向量，而 
Σ是共變異矩陣(稍後述)。
在一維的情況下，我們還可以把累積分佈函數 
F(x)定義為一個隨機變數小於 
x的機率。對於常
態分佈，即為 


1 x.μ

() = 
() z= 
(1 + 
erf( 

Fx Pzd

))

∫(x) 

.∞ 
2 σ 
2 

其中 
erf(x)就是所謂的誤差函數，它沒有封閉形式的表示方式。

中央極限定理所述為：取 
n個獨立隨機變數、再取其平均後所得之分佈，在 
n趨近無窮大時，
此分佈會趨近於常態分佈。這個結論對幾乎任何隨機變數的集合都成立，即使他們不是嚴格獨立，
除非有變數所成的任意有限子集合其變異數遠超過其他子集合的貢獻。

隨機變數的期望值 
()

EX是各值以各自機率作權重後所得之平均值。對於離散變數，其為： 


EX() = 
xPX ( = 
x)

Σii 
i 


對於連續變數，將總和換成對機率密度函數 
()

Px的積分： 


() = 
x() 

EX Pxdx

∫(∞) 

.∞ 


一組值(通常為一個隨機變數的取樣)的方均根 
RMS為這些值的平方和取平均後的開根值， 


22

x ++... xRMSx ( 1,..., xn) =1 n 

n 

兩隨機變數的共變異數為，兩者與各自平均間之差值作互乘後，該乘積的期望值： 


cov( ,) = 
EX (( .μxY.μy)) 

XY )( 

共變異矩陣(常記為 
Σ)是隨機變數所成之向量其元素間的共變異數矩陣。給定 
X=


X1,..., Xn 
T ，共
變異矩陣為如下： 


ij, cov( i, j) = 
EX(( i.μi)(Xj.μ 
j))

Σ= 
XX 
幾個較瑣碎的事項：我們用 
log( )x代表自然對數 
log( )x。我們用 
arg max fx代表使

ex () f()x為極大的 


x值。


附錄 


.App-7. 
..參考文獻與歷史的註釋 
BIBLIOGRAPHICAL AND HISTORICAL NOTES
當今在資訊科學中如此廣泛使用的符號 
O()，最早是在數論的發展脈絡中，由德國數學家 
P.G.H. 
Bachmann(1894)所引進採用。 
NP-completeness的概念是 
Cook(1971)所發明，而將從一個問題簡化為
另一個問題的現代方法則要歸功於 
Karp(1972)。由於他們的工作，Cook和 
Karp雙雙獲得資訊科學
界的最高榮譽——圖靈獎(Turing Award)。

演算法的分析與設計的經典作品包括了 
Knuth(1973)及 
Aho、Hopcroft和 
Ullman(1974)的著作；
更近一些的貢獻則包括 
Tarjan(1983)以及 
Cormen、Leiserson和 
Rivest(1990)的著作。這些書籍強調了
對演算法作設計與分析，以解決容易問題(tractable problem)。對於 
NP-completeness的理論及其他形
式的難解性(intractability)，參見 
Garey和 
Johnson(1979)或 
Papadimitriou(1994)。機率論的好課本包括 
Chung (1979)、Ross (1988)、Bertsekas及 
Tsitsiklis (2008)。


